# 1章
- webサービスを高速化するには必要十分なキャパシティを揃える必要がある
- パフォーマンスチューニングのきほんのき
  - いきなり手を動かさない
  - 推測せず計測する
  - 公平に計測する
    - 前提条件を揃える
  - 一つずつ計測する
    - いわゆる対象実験をしてボトルネックを確実に絞り込む
- パフォーマンスチューニングのきほんのほ
  - ボトルネックにだけアプローチする
    - それ以外にアプローチしてもあまり効果はないしなんなら悪化する可能性もある
  - ボトルネックの特定は外側から順番に
    - どんどん範囲を狭めて原因を特定していく
      - ex)mySQLに原因がある->悪いクエリを探す->改善する
- ボトルネック対処の基本3パターン
  - 解決：課題になっている事象を根本から解決する 
  - 回避：課題になっている事象がボトルネックにならないよう迂回・省略する 
  - 緩和：課題になっている事象の影響を和らげる
- パフォーマンスチューニングのきほんのん
  - 負荷試験を何度も行って試行錯誤する
  - 試験計画をきちんと立てる
  - 負荷をかけながら手動でも利用してみて使用感を確かめると良い 
  - 実施時間・実施結果・メトリクス・ログをセットで自動的に記録しておくと良い
  - 実施結果の内容を都度解釈する 
    - パフォーマンス：X並列でYユーザーがN分間で操作完了 
    - 異常の有無：エラーレスポンス、システムエラー、不審な挙動、不安定なレスポンスタイム ・ボトルネックは移動したか 
    - それぞれの値、リソースメトリクスの値が想定通りに変化したか 
  - 与負荷環境側のメトリクスも同時に確認する（与負荷側がボトルネックになり、十分な負荷が生成できないケースもままある）


# 2章 モニタリング
- モニタリングは2種類
  - 外形監視
    - アプリの外側からモニタリングすること
    - Synthetic Montoringともいわれる
    - できるだけユーザーの近くから行うことネットワーク的な接続トラブルが発見できるという利点がある
      - 多くの場合ではユーザーが不特定多数であることから完全な再現は現実的ではないため、ある程度コストと天秤にかけて決定
  - 内部監視
- モニタリングツールのアーキテクチャ
  - プル型
    - モニタリングアプリケーションが対象アプリ内のエージェントへメトリクスを取得するアーキテクチャ
    - メトリクスの取得間隔をモニタリングアプリケーション側から管理できたり、エージェント側の実装をシンプルにできる
  - プッシュ型
    - アプリ内部のエージェントがモニタリングアプリケーションへメトリクスを送信するアーキテクチャ
    - エージェントが動作しているサーバーにおけるポートに対する接続を許可する必要がない
    - モニタリングアプリケーション側の設定を変更せずともモニタリング対象の増減が可能になる
- モニタリングの注意点
  - 正しい計測結果の見極め
  - 2つのグラフを比較するときは他の条件を合わせる
    - よくあるミスとして、異なる原点を定めたグラフを比較するということがある
  - 高負荷状態のモニタリング
    - 負荷試験などで計測する際には負荷試験のために発生する負荷についても考慮が必要
    - 負荷試験を行う環境は実際に本番環境で運用する環境にできるだけ近づけるべき
  - メトリクスの取得感覚は適切なものを設定すること
    - 解像度が低い、足りていない状態では細かな負荷の変化を見つけられない
    - できるだけリアルタイムに解像度が高くなるようにしておくことで、隠れていた異常を見つけることが可能

# 3章 基礎的な負荷試験
- パフォーマンスチューニングにおいては、「負荷試験の実行と負荷の観察」→「観察結果に基づいたチューニング」→「再度の負荷試験で実施したチューニングが有効かどうか確認する」というサイクルを回していく必要がある
- 並列度を上げていくことによってうまく使えていないリソースを発見できる
- 一般的に、1プロセスで1リクエストを処理するアーキテクチャの場合、workerプロセスはCPU数より大きく（典型的にはCPU数の数倍に）するのが一般的
- 動作するプロセスが増えればそれだけメモリも消費し、CPUの割り込みやコンテキストスイッチと呼ばれる処理も増加する

# 4章 シナリオをもった負荷試験
- 実際にユーザーが行うシナリオをモニタリングすることでもボトルネックは発見できる

# 5章 データベースのチューニング
- DBのプロセスを確認する
  - 何度も表示されるクエリはWebアプリケーションから数多く実行されているか、1回の実行時間が長く表示されやすいか、もしくはその両方で負荷が高いクエリである可能性がある
- 実行されたクエリを集めて解析するには、スロークエリログがよく利用される
  - 設定した閾値より実行にかかった時間が長くなったクエリを、かかった秒数や処理した行数とともに出力したログ
- プライマリインデックス
  - いわゆる主キーで作られるインデックス
  - ユニークな値で各エンティティに一つだけ
  - プライマリインデックスの先にデータを用意するクラスターインデックスがある
- セカンダリインデックス
  - 任意で作るインデックス
  - 主キーが葉にあり、その値でプライマリインデックスを検索する
- Covering Index
  - セカンダリインデックスでもcountなどidがわかればいいという理論の最適化
- インデックスはソート済みのもう1つのデータベースになる
  - インデックスの作成、データの追加・更新があった場合のインデックス更新には、オーバーヘッドが伴う
  - インデックスの数が増えれば、その負荷は増えていき、データ更新時に負荷が高まったり、速度が落ちたりする原因となる。
- like等の検索には全文検索インデックスを用いるといい
- 空間インデックスもある(詳しく載ってないのであとから探す)
- N+1問題の対策
  - joinを用いる
  - キャッシュを用いた回避も可能
    - NoSQL(memcachedやRedisなど)
    - メモ化再帰とかと感覚は近い
  - 別クエリによるプリロードを用いたN+1の解決
    - in句を用いて回数を抑える
    - IN句に渡す値の数が多過ぎると、クエリのサイズが大きくなり過ぎてエラーになったり、狙ったインデックスが使われなかったりする
  - 正規化をわざと崩す
    - JOINして取得したい情報をあらかじめテーブルにも格納しておくことでシンプルなクエリのままN+1問題を解消する
    - 長期に利用するWebサービスではデータが冗長になり、更新時のコストが高くなるリスクもありますが、高速化の目的がはっきりしている場面では利用可能な手法
  - N+1問題はデータベースだけに限った話ではない
    - 外部サービスにアクセスして情報を取得する場合にも発生する
    - Webサービスのパフォーマンスに影響するようであれば、必要な情報をバルクで取得するAPIを用意し、活用するなどの対策が必要
- MySQLのバージョンやテーブルに作成されているインデックスによっては、開発者の想定と異なる実行計画が取られることがある
  - FORCE INDEXとSTRAIGHT_JOINを用いてヒントを与えることによって解決できる
  - FORCE INDEX
    - インデックスを強制指定するキーワード
  - STRAIGHT_JOIN
    - クエリを上から順にできるキーワード
- SELECTで必要なカラムを指定することでもパフォーマンスが改善する
  - 画像とかは特に
- プリペアドステートメント
  - DBのクエリにおけるキャッシュのようなもの
  - あくまでも取得結果ではなくクエリに対するキャッシュであることに注意
- DBには最大同時接続数が設定されている
  - ここもチューニングの対象
  - 永続的に接続した方がいい?

# 6章 リバースプロキシの利用
- リバースプロシキの主な役割は以下の三つ
  - 負荷分散（ロードバランス）
  - コンテンツのキャッシュ
  - HTTPS通信の終端
- パフォーマンスに影響しやすいものとしては以下がある
  - 転送時のデータ圧縮
  - リクエストとレスポンスのバッファリング
  - リバースプロキシとアップストリームサーバーのコネクション管理
- プロセス・スレッドに関するアーキテクチャ
  - マルチプロセス・シングルスレッド
    - クライアントからの1リクエストを1プロセスが処理を行っている
    - そのプロセスは処理を行っている間に他のリクエストを処理できまない
    - そのため、このアーキテクチャではプロセス数と同時に処理できるリクエスト数が一致す
    - プロセス数が同時に扱えるリクエスト数の上限であっても、大量のリクエストが来ない限りは十分なパフォーマンスを出せる
    - 同時に大量のリクエストが来る場合はC10K問題が起きる
      - アクセスするクライアント数が1万を超えると、サーバーのスレッド（並列処理の単位）数が増え、サーバーのメモリーなどのリソースが不足してしまう問題
  - シングルプロセス・マルチスレッド
    - 同じプロセス上のメモリ空間をスレッド同士が共有できるため、使用するメモリが少なく済む
    - しかし、スレッドを切り替える時も先程と同様にコンテキストスイッチが発生するの
    - 1スレッドがレスポンスを返すまで占有されるアーキテクチャにすると先程と同様にC10K問題が発生
- アプリケーションサーバーの前にnginxなど他のアーキテクチャで作られたリバースプロキシを前段に置く構成のメリット
  - 遅いクライアントとの通信でアプリケーションサーバーのプロセスが専有されなくなります。
    - 回線が細いなどの理由で遅いクライアントにレスポンスを返す際もリバースプロキシがレスポンスを返してくれるため、
  - 画像・CSS・JavaScriptをリバースプロキシで直接静的ファイルを返した方がパフォーマンスは上がります
    - アプリケーション側で操作が不要なため
- nginx
  - リバースプロキシとして利用される代表的なソフトウェア
    - nginxでは設定ファイルを書くことでリバースプロキシとしてアップストリームに指定したアプリケーションサーバーにリクエストを送ったり、直接静的ファイルを配信できる
    - Mainline versionとStable versionの2種類のバージョンが用意されている
    - nginxは1つのサーバーで複数の設定が異なるHTTPサーバーをそれぞれ動作させることができる
      - ドメインを運用する技術であるバーチャルホストに対応しているため、
  - アーキテクチャ
    - マルチプロセス・シングルスレッド
    - イベント駆動のアーキテクチャを採用している
      - 各プロセスが複数のクライアントからのリクエスト・レスポンスを並行して扱うことができる
    - 多重I/OやノンブロッキングI/Oを用いている
      - ノンブロッキングI/O:通信を待っている際にリソースをブロックしない
  - gzipに対応したHTTPクライアントからのリクエストに対して、gzipを使用して圧縮したレスポンスを返すことができる
    - 圧縮レベルを上げると圧縮度を上げられる
      - 圧縮処理に時間がかかるのでトレードオフである
    - gzip圧縮する場所も重要
      - プロシキサーバだけでなくアプリケーションサーバでも圧縮を検討する
  - アップストリームサーバーのコネクション管理
    - キープアライブを利用することで、アップストリームサーバーへの接続処理を減らすことができる
      - コネクションを保持して使い回すこと
      - 大量のリクエストを受け付けるサーバーの場合、コネクションを頻繁に作り直すとパフォーマンスが落ちたり、負荷が上がって適切に動かなくなることがある

# 7章 キャッシュの活用
- キャッシュを利用する場合はキャッシュしたデータをどこに保存するか決める必要があり
- キャッシュを利用するミドルウェアには以下があればいい
  - keyからvalueが取得できるKVSとしての機能
  - TTLを定められ、TTLがすぎたらexpireしてデータを削除する機能
- memcached
  - メリット
    - KVSとして必要な機能を持っている
    - パフォーマンスが非常に高い
    - 特にPHP接続を永続化できるなど、非常に工夫されている
  - デメリット
    - ストレージを永続化できない
    - レプリケーション機能がないため再起動や障害などで簡単にデータが失われてしまう
  - 消えても困らないキャッシュとして以外の用途は想定されていない
- Redis
  - メリット
      - KVSとしての機能以外にもさまざまな機能を持っている
      - コマンドや扱えるデータ構造も多い
      - データの永続化やレプリケーションの機能もある
      - Redis ClusterやRedis Sentinelなどを使用することでクラスター構成に組むことも可能
    - デメリット
      - 基本的にシングルスレッドで動作するため、単純なGET/SET以外のコマンドを実行する場合に、1クライアントの処理で長時間全体の処理がブロックしてしまう可能性がある
      - 単純なKVSではない使い方をする場合は、発行するコマンドによってパフォーマンスを出しにくいことがある
- キャッシュデータをWebアプリケーションのインメモリに保存する方法もある
  - ミドルウェアとの通信コストが不要になるため、Webアプリケーション上で高速に動作する
  - シングルプロセス・マルチスレッドのアーキテクチャの場合、並行に読み込み・書き込みができるように適切なロックを取る必要がある
  - マルチプロセス・シングルスレッドのアーキテクチャの場合、簡単にはプロセス間でメモリを共有できない
  - 実装によってはTTLの実装を自分でする必要がある
  - デプロイした時やサーバー追加時にキャッシュがないため、デプロイした直後のパフォーマンス劣化や、デプロイ直後にThundering herd problem（詳しくは後述）が発生し、データベースなどに負荷が集中する可能性がある
  - アクセスが集中したことを理由にサーバーを追加する場合、キャッシュが存在しないサーバーを追加することでデータベースなどの負荷が更に増すなど、状況を悪化させる可能性がある ●問題のあるデータをキャッシュしたときに簡単に消せないことが多い
- キャッシュをサーバー上のファイルに保存する方法もある
  - こちらもサーバー追加時にキャッシュがない状態から始まるので、インメモリキャッシュ同様のデメリットある
- インメモリやファイルによるキャッシュはミドルウェアへのリクエストを減らしたいときに補助的に利用するのが吉
  - インメモリやファイルによるキャッシュは扱いにくいことが多い
  - インメモリキャッシュのメリットである高速というメリットを享受しつつ、デメリットも減らせる
- キャッシュを用いるメリット
  - CPUへの負荷が大きな処理や時間がかかる処理の実行回数を抑えられるので、パフォーマンスが上がる 
  - インフラコストも下げられる 
  - 外部APIを使用している場合は外部APIの呼び出し回数に制限がある（レートリミット）ことが多い
    - その場合はその制限に達しないようにキャッシュを利用する必要がある
  - 大量のリクエストに耐えられる仕組みが比較的容易に作れる
- デメリット
  - 古いデータが表示されることがある
    - データ上、不整合が発生することもある
    - データ更新時にキャッシュの削除・更新を適切に行うことで、ある程度軽減できる
  - キャッシュを保存するミドルウェアが新しいWebサービス上の障害点になる
    - ミドルウェアの空き容量の不足がないかなど正しく動作しているか監視をする必要がある
    - ミドルウェアの再起動などによってミドルウェアに保存したデータが一気に失われることもある
  - 想定外のデータを表示してしまい、情報流出に繋がる可能性がある
     -  重大なセキュリティリスクになることもある
  -  プログラムの実装が複雑になるため、問題が起こったときの原因究明の難易度が上がる
  -  キャッシュに乗っていないタイミングで大量にリクエストが来ると、実装によってはキャッシュ生成の重い処理が大量に同時実行されることがある
     -  Thundering herd problemと呼ばれる問題
- 以下のことを考えて導入するといい
- データの不整合がどこまで許されるか
  - 決済情報など重要なデータは不整合が致命的になるので、キャッシュを使うべきではない
  - 更新したはずのデータが更新されないとユーザーからバグを疑われる
- データの特性上、本当にキャッシュを使う必要があるか
  - ユーザー情報などはユーザー毎にキャッシュが分散するため、有効にキャッシュを使えない可能性がある
  - 有効に使えないキャッシュが増えると、キャッシュを保存するミドルウェアの容量が足りなくなる可能性がある
  - ユーザー情報を取り違えると、重大なセキュリティリスクに繋がる可能性がある
- データの更新頻度はどの程度か
  - データが頻繁に更新される場合、キャッシュをしても有効に活用できない可能性がある
  - データの鮮度が重要な機能の場合、更新頻度が低いとユーザー体験が悪化する
- データの生成コストを考えているか
  - 生成コストが低いならキャッシュを使う必要はない
  - 生成コストが高すぎる場合、キャッシュデータが失われると長時間復旧できないため、生成結果をRDBMSなどデータが失われにくいデータベースに保存する必要がある
- キャッシュにおいては十分短いTTLを設定する必要がある
- データが更新されたときにキャッシュも同時に更新するようにする
- Thundering herd problem
  - キャッシュがない段階でサーバーに大量にリクエストを投げることで高負荷になってしまう問題
    - この場合、キャッシュが作成されていない状態で大量にリクエストを投げるのでキャッシュが活用できずに高負荷になってしまう
  - 対策
    - キャッシュの残り時間も取得し、そのキャッシュの残り時間が指定した時間を下回っている場合は一定の確率でexpireしているとみなし、キャッシュの再構築をする実装をする
    - キャッシュがなければデフォルト値や古いキャッシュを返し、非同期にキャッシュ更新処理を実行する
      - メリット
        - レスポンスはほとんどのケースで高速に返せる
        - アクセスがあったものだけキャッシュを生成するため効率的
      - デメリット
        - ロジックが複雑
        - キャッシュ更新を非同期に行うため、ジョブキューなどの非同期に処理を実行できる仕組みが必要
        - キャッシュがなければデフォルト値を返す実装の場合、キャッシュがないタイミングでリクエストした人には適切なレスポンスを返せない
          - 古いキャッシュを返す場合も、本来なら使うべきでない古いキャッシュを使用している
        - Thundering herd problemは解決していない
          - キャッシュ更新時の処理が複数実行されないようにする仕組みは別に必要
    - バッチ処理などで定期的にキャッシュを更新する
      - メリット
        - 実装は比較的簡単
        - Thundering herd problemが発生しない
      - バッチで生成できるデータにしか使えない
      - アクセスがほぼ来ないデータも事前に生成する必要があるので、ほぼ使われないキャッシュも管理する必要がある
      - 障害でキャッシュが揮発したときに復旧に時間がかかる可能性がある
        - キャッシュが存在しなければ、データを取得できないためエラーになってしまう
        - バッチを実行すれば復旧できるはずだが、実行する必要があるバッチが大量にある場合は復旧の難易度が高い
- キャッシュの監視
  - 以下の二つを監視する必要がある
    - expireしていないのにキャッシュから追い出されたアイテム数(evicted items)
    - キャッシュヒット率(cache-hit ratio)

# 8章 抑えておきたい高速化手法
# 9章 OSの基礎知識とチューニング
