# 1章
- webサービスを高速化するには必要十分なキャパシティを揃える必要がある
- パフォーマンスチューニングのきほんのき
  - いきなり手を動かさない
  - 推測せず計測する
  - 公平に計測する
    - 前提条件を揃える
  - 一つずつ計測する
    - いわゆる対象実験をしてボトルネックを確実に絞り込む
- パフォーマンスチューニングのきほんのほ
  - ボトルネックにだけアプローチする
    - それ以外にアプローチしてもあまり効果はないしなんなら悪化する可能性もある
  - ボトルネックの特定は外側から順番に
    - どんどん範囲を狭めて原因を特定していく
      - ex)mySQLに原因がある->悪いクエリを探す->改善する
- ボトルネック対処の基本3パターン
  - 解決：課題になっている事象を根本から解決する 
  - 回避：課題になっている事象がボトルネックにならないよう迂回・省略する 
  - 緩和：課題になっている事象の影響を和らげる
- パフォーマンスチューニングのきほんのん
  - 負荷試験を何度も行って試行錯誤する
  - 試験計画をきちんと立てる
  - 負荷をかけながら手動でも利用してみて使用感を確かめると良い 
  - 実施時間・実施結果・メトリクス・ログをセットで自動的に記録しておくと良い
  - 実施結果の内容を都度解釈する 
    - パフォーマンス：X並列でYユーザーがN分間で操作完了 
    - 異常の有無：エラーレスポンス、システムエラー、不審な挙動、不安定なレスポンスタイム ・ボトルネックは移動したか 
    - それぞれの値、リソースメトリクスの値が想定通りに変化したか 
  - 与負荷環境側のメトリクスも同時に確認する（与負荷側がボトルネックになり、十分な負荷が生成できないケースもままある）


# 2章 モニタリング
- モニタリングは2種類
  - 外形監視
    - アプリの外側からモニタリングすること
    - Synthetic Montoringともいわれる
    - できるだけユーザーの近くから行うことネットワーク的な接続トラブルが発見できるという利点がある
      - 多くの場合ではユーザーが不特定多数であることから完全な再現は現実的ではないため、ある程度コストと天秤にかけて決定
  - 内部監視
- モニタリングツールのアーキテクチャ
  - プル型
    - モニタリングアプリケーションが対象アプリ内のエージェントへメトリクスを取得するアーキテクチャ
    - メトリクスの取得間隔をモニタリングアプリケーション側から管理できたり、エージェント側の実装をシンプルにできる
  - プッシュ型
    - アプリ内部のエージェントがモニタリングアプリケーションへメトリクスを送信するアーキテクチャ
    - エージェントが動作しているサーバーにおけるポートに対する接続を許可する必要がない
    - モニタリングアプリケーション側の設定を変更せずともモニタリング対象の増減が可能になる
- モニタリングの注意点
  - 正しい計測結果の見極め
  - 2つのグラフを比較するときは他の条件を合わせる
    - よくあるミスとして、異なる原点を定めたグラフを比較するということがある
  - 高負荷状態のモニタリング
    - 負荷試験などで計測する際には負荷試験のために発生する負荷についても考慮が必要
    - 負荷試験を行う環境は実際に本番環境で運用する環境にできるだけ近づけるべき
  - メトリクスの取得感覚は適切なものを設定すること
    - 解像度が低い、足りていない状態では細かな負荷の変化を見つけられない
    - できるだけリアルタイムに解像度が高くなるようにしておくことで、隠れていた異常を見つけることが可能

# 3章 基礎的な負荷試験
- パフォーマンスチューニングにおいては、「負荷試験の実行と負荷の観察」→「観察結果に基づいたチューニング」→「再度の負荷試験で実施したチューニングが有効かどうか確認する」というサイクルを回していく必要がある
- 並列度を上げていくことによってうまく使えていないリソースを発見できる
- 一般的に、1プロセスで1リクエストを処理するアーキテクチャの場合、workerプロセスはCPU数より大きく（典型的にはCPU数の数倍に）するのが一般的
- 動作するプロセスが増えればそれだけメモリも消費し、CPUの割り込みやコンテキストスイッチと呼ばれる処理も増加する

# 4章 シナリオをもった負荷試験
- 実際にユーザーが行うシナリオをモニタリングすることでもボトルネックは発見できる

# 5章 データベースのチューニング
- DBのプロセスを確認する
  - 何度も表示されるクエリはWebアプリケーションから数多く実行されているか、1回の実行時間が長く表示されやすいか、もしくはその両方で負荷が高いクエリである可能性がある
- 実行されたクエリを集めて解析するには、スロークエリログがよく利用される
  - 設定した閾値より実行にかかった時間が長くなったクエリを、かかった秒数や処理した行数とともに出力したログ
- プライマリインデックス
  - いわゆる主キーで作られるインデックス
  - ユニークな値で各エンティティに一つだけ
  - プライマリインデックスの先にデータを用意するクラスターインデックスがある
- セカンダリインデックス
  - 任意で作るインデックス
  - 主キーが葉にあり、その値でプライマリインデックスを検索する
- Covering Index
  - セカンダリインデックスでもcountなどidがわかればいいという理論の最適化
- インデックスはソート済みのもう1つのデータベースになる
  - インデックスの作成、データの追加・更新があった場合のインデックス更新には、オーバーヘッドが伴う
  - インデックスの数が増えれば、その負荷は増えていき、データ更新時に負荷が高まったり、速度が落ちたりする原因となる。
- like等の検索には全文検索インデックスを用いるといい
- 空間インデックスもある(詳しく載ってないのであとから探す)
- N+1問題の対策
  - joinを用いる
  - キャッシュを用いた回避も可能
    - NoSQL(memcachedやRedisなど)
    - メモ化再帰とかと感覚は近い
  - 別クエリによるプリロードを用いたN+1の解決
    - in句を用いて回数を抑える
    - IN句に渡す値の数が多過ぎると、クエリのサイズが大きくなり過ぎてエラーになったり、狙ったインデックスが使われなかったりする
  - 正規化をわざと崩す
    - JOINして取得したい情報をあらかじめテーブルにも格納しておくことでシンプルなクエリのままN+1問題を解消する
    - 長期に利用するWebサービスではデータが冗長になり、更新時のコストが高くなるリスクもありますが、高速化の目的がはっきりしている場面では利用可能な手法
  - N+1問題はデータベースだけに限った話ではない
    - 外部サービスにアクセスして情報を取得する場合にも発生する
    - Webサービスのパフォーマンスに影響するようであれば、必要な情報をバルクで取得するAPIを用意し、活用するなどの対策が必要
- MySQLのバージョンやテーブルに作成されているインデックスによっては、開発者の想定と異なる実行計画が取られることがある
  - FORCE INDEXとSTRAIGHT_JOINを用いてヒントを与えることによって解決できる
  - FORCE INDEX
    - インデックスを強制指定するキーワード
  - STRAIGHT_JOIN
    - クエリを上から順にできるキーワード
- SELECTで必要なカラムを指定することでもパフォーマンスが改善する
  - 画像とかは特に
- プリペアドステートメント
  - DBのクエリにおけるキャッシュのようなもの
  - あくまでも取得結果ではなくクエリに対するキャッシュであることに注意
- DBには最大同時接続数が設定されている
  - ここもチューニングの対象
  - 永続的に接続した方がいい?

# 6章 リバースプロキシの利用
- リバースプロシキの主な役割は以下の三つ
  - 負荷分散（ロードバランス）
  - コンテンツのキャッシュ
  - HTTPS通信の終端
- パフォーマンスに影響しやすいものとしては以下がある
  - 転送時のデータ圧縮
  - リクエストとレスポンスのバッファリング
  - リバースプロキシとアップストリームサーバーのコネクション管理
- プロセス・スレッドに関するアーキテクチャ
  - マルチプロセス・シングルスレッド
    - クライアントからの1リクエストを1プロセスが処理を行っている
    - そのプロセスは処理を行っている間に他のリクエストを処理できまない
    - そのため、このアーキテクチャではプロセス数と同時に処理できるリクエスト数が一致す
    - プロセス数が同時に扱えるリクエスト数の上限であっても、大量のリクエストが来ない限りは十分なパフォーマンスを出せる
    - 同時に大量のリクエストが来る場合はC10K問題が起きる
      - アクセスするクライアント数が1万を超えると、サーバーのスレッド（並列処理の単位）数が増え、サーバーのメモリーなどのリソースが不足してしまう問題
  - シングルプロセス・マルチスレッド
    - 同じプロセス上のメモリ空間をスレッド同士が共有できるため、使用するメモリが少なく済む
    - しかし、スレッドを切り替える時も先程と同様にコンテキストスイッチが発生するの
    - 1スレッドがレスポンスを返すまで占有されるアーキテクチャにすると先程と同様にC10K問題が発生
- アプリケーションサーバーの前にnginxなど他のアーキテクチャで作られたリバースプロキシを前段に置く構成のメリット
  - 遅いクライアントとの通信でアプリケーションサーバーのプロセスが専有されなくなります。
    - 回線が細いなどの理由で遅いクライアントにレスポンスを返す際もリバースプロキシがレスポンスを返してくれるため、
  - 画像・CSS・JavaScriptをリバースプロキシで直接静的ファイルを返した方がパフォーマンスは上がります
    - アプリケーション側で操作が不要なため
- nginx
  - リバースプロキシとして利用される代表的なソフトウェア
    - nginxでは設定ファイルを書くことでリバースプロキシとしてアップストリームに指定したアプリケーションサーバーにリクエストを送ったり、直接静的ファイルを配信できる
    - Mainline versionとStable versionの2種類のバージョンが用意されている
    - nginxは1つのサーバーで複数の設定が異なるHTTPサーバーをそれぞれ動作させることができる
      - ドメインを運用する技術であるバーチャルホストに対応しているため、
  - アーキテクチャ
    - マルチプロセス・シングルスレッド
    - イベント駆動のアーキテクチャを採用している
      - 各プロセスが複数のクライアントからのリクエスト・レスポンスを並行して扱うことができる
    - 多重I/OやノンブロッキングI/Oを用いている
      - ノンブロッキングI/O:通信を待っている際にリソースをブロックしない
  - gzipに対応したHTTPクライアントからのリクエストに対して、gzipを使用して圧縮したレスポンスを返すことができる
    - 圧縮レベルを上げると圧縮度を上げられる
      - 圧縮処理に時間がかかるのでトレードオフである
    - gzip圧縮する場所も重要
      - プロシキサーバだけでなくアプリケーションサーバでも圧縮を検討する
  - アップストリームサーバーのコネクション管理
    - キープアライブを利用することで、アップストリームサーバーへの接続処理を減らすことができる
      - コネクションを保持して使い回すこと
      - 大量のリクエストを受け付けるサーバーの場合、コネクションを頻繁に作り直すとパフォーマンスが落ちたり、負荷が上がって適切に動かなくなることがある

# 7章 キャッシュの活用
# 8章 抑えておきたい高速化手法
# 9章 OSの基礎知識とチューニング
